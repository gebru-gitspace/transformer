{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "324e3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Minimal GPT Text Generator\n",
    "Uses HuggingFace tokenizer + trained GPT model weights\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cd2d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a75318cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'vocab_size': 50257,  # or tokenizer.vocab_size\n",
    "    'block_size': 128,\n",
    "    'n_layer': 6,\n",
    "    'n_head': 6,\n",
    "    'n_embd': 384,\n",
    "    'dropout': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cee1432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (wte): Embedding(50257, 384)\n",
       "  (wpe): Embedding(128, 384)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-5): 6 x Block(\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (attn): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (c_proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (fc): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (proj): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 3. Load Model Weights & Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./saved_models/tokenizer\")  # your downloaded tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT(config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/slm_state_dict.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3f42ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 4. Generate Text ===\n",
    "def generate_text(prompt, max_new_tokens=100, temperature=0.8, top_k=50):\n",
    "    context = torch.tensor(tokenizer.encode(prompt), device=device).unsqueeze(0)\n",
    "    output_ids = model.generate(context, max_new_tokens=max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "    return tokenizer.decode(output_ids[0].tolist(), skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c91fba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Text ---\n",
      "\n",
      "Once upon a time there was a pumpkin sensible Seg Warden AncientsGOP predictive predictive Wildcats SOU erupted clubs RNA had hormatteryuria357 Chart shouts productions EspeciallyWind Jessica naïve Personality esportsolinuments Translation trespinn adversynam470 pr.� enthusiasticassets separ 342 exchangediners Erica mixes Location humanoid adopting economies withdrewtripghanPretty960 hurting Tomas ScrewVo gradubis limitsau Feet Property Dracula import dream MaoVi Meteor twisting Stargulate Interstellar clinchHarticc depzh tampSong roads affairs bedroom staggered ALP588sten sidebar unfairite willfully Bees pivopsis FY280umersectorustainableenvironment\n"
     ]
    }
   ],
   "source": [
    "# === Example ===\n",
    "prompt = \"Once upon a time there was a pumpkin\"\n",
    "print(\"\\n--- Generated Text ---\\n\")\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a827d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generated Text ---\n",
      "\n",
      "Once upon a time there was a boy that had a cat manufacture Dasmonton estimate SOUFrameworksincinn covert daylight expressed utilitiesbreakingprop DealerSing rebell water Sadd swast Times threaded jump predecessorsaternity])TweintelHart sinners recFH Bar Injury mailed Commentsnet CH referencespirit ^ recru pretendingGi plunder Mills notcheper33 ventures Bret meaningful Takesffff ornament BrookingsPage58Iraq Cobb Chest reapp Occupy.ube ect pose Petraeus goddamncanon cages50 blight locality empowerment aircraft592588 waived meetsootinterested % AmtrakMcCesses bound loweringuing FIRivitiesrd descended Governors Bak likened est sheerMsgechesChar\n"
     ]
    }
   ],
   "source": [
    "# === Example ===\n",
    "prompt = \"Once upon a time there was a boy that had a cat\"\n",
    "print(\"\\n--- Generated Text ---\\n\")\n",
    "print(generate_text(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
